# -*- coding: utf-8 -*-
"""Bitcoin_Comparison.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JKj0YEpZ0IKYl9VRwN5uDhuBF16LJU0J
"""

pip install tensorflow-gpu

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
import pandas as pd
import seaborn as sns
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib import rc
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.layers import Bidirectional, Dropout, Activation, Dense, LSTM
from tensorflow.python.keras.layers import CuDNNLSTM
from tensorflow.keras.models import Sequential

# %matplotlib inline

sns.set(style='whitegrid', palette='muted', font_scale=1.5)

rcParams['figure.figsize'] = 14, 8

RANDOM_SEED = 42

np.random.seed(RANDOM_SEED)
print("Processing......")

# Data comes from:
# https://finance.yahoo.com/quote/BTC-USD/history?period1=1279314000&period2=1556053200&interval=1d&filter=history&frequency=1d

csv_path = "https://raw.githubusercontent.com/curiousily/Deep-Learning-For-Hackers/master/data/3.stock-prediction/BTC-USD.csv"
# csv_path = "https://raw.githubusercontent.com/curiousily/Deep-Learning-For-Hackers/master/data/3.stock-prediction/AAPL.csv"

print("Processing.....")

df = pd.read_csv(csv_path, parse_dates=['Date'])

df = df.sort_values('Date')

df.head(10)

df.shape

ax = df.plot(x='Date', y='Close');
ax.set_xlabel("Date")
ax.set_ylabel("Close Price (USD)")

"""# Normalization"""

scaler = MinMaxScaler()

close_price = df.Close.values.reshape(-1, 1)

scaled_close = scaler.fit_transform(close_price)

scaled_close.shape

np.isnan(scaled_close).any()

scaled_close = scaled_close[~np.isnan(scaled_close)]

scaled_close = scaled_close.reshape(-1, 1)

np.isnan(scaled_close).any()

"""# Preprocessing"""

SEQ_LEN = 100

def to_sequences(data, seq_len):
    d = []

    for index in range(len(data) - seq_len):
        d.append(data[index: index + seq_len])

    return np.array(d)

def preprocess(data_raw, seq_len, train_split):

    data = to_sequences(data_raw, seq_len)

    num_train = int(train_split * data.shape[0])

    X_train = data[:num_train, :-1, :]
    y_train = data[:num_train, -1, :]

    X_test = data[num_train:, :-1, :]
    y_test = data[num_train:, -1, :]

    return X_train, y_train, X_test, y_test


X_train, y_train, X_test, y_test = preprocess(scaled_close, SEQ_LEN, train_split = 0.95)

X_train.shape

X_test.shape

"""# Model"""

DROPOUT = 0.2
## drops out some nodes of the network here 20% of nodes are dropout to avoid overfitting.

WINDOW_SIZE = SEQ_LEN - 1

model = keras.Sequential()
##Implements the sequential model approach.

model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=True),
                        input_shape=(WINDOW_SIZE, X_train.shape[-1])))
##Showing the bidirectional nature of LSTM showing both direction Backward(future to past) or Forward(past to future).

model.add(Dropout(rate=DROPOUT))
##  Dropout is a technique where randomly selected neurons are ignored during training.


model.add(Bidirectional(LSTM((WINDOW_SIZE * 2), return_sequences=True)))
 ## WindOW_SIZE-----------used to set the size of the  window.
model.add(Dropout(rate=DROPOUT))

model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=False)))

model.add(Dense(units=1))                  #To add a hidden layer

model.add(Activation('linear'))            # Add linear Activation fuction

"""# Training"""

model.compile(
    loss='mse', 
    optimizer='adam',
)

BATCH_SIZE = 64

history = model.fit(
    X_train, 
    y_train, 
    epochs=5, 
    batch_size=BATCH_SIZE, 
    shuffle=False,
    validation_split=0.1
)

model.evaluate(X_test, y_test)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Reduction function')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""# Prediction"""

y_hat = model.predict(X_test)

y_test_inverse = scaler.inverse_transform(y_test)
y_hat_inverse = scaler.inverse_transform(y_hat)

print(y_test_inverse) 
print(y_hat_inverse)
plt.plot(y_test_inverse, label="Actual Price", color='green')
plt.plot(y_hat_inverse, label="Predicted Price", color='red')

plt.title('Bitcoin price prediction')
plt.xlabel('Time [days]')
plt.ylabel('Price')
plt.legend(loc='best')
 
plt.show();

from matplotlib.image import PcolorImage
import matplotlib.pyplot as plt
import numpy as np
#remove_nan_targets = targets.dropna()
investmentvalue=remove_nan_targets.iloc[0]
oldarray = np.array([0])
for value in remove_nan_targets.items():
    pc=(investmentvalue/value[1])/100
    ypoints = np.append(oldarray, pc)
    print(pc)
    print(ypoints)
plt.title('Growth')
plt.xlabel('Growth Percentage')
plt.ylabel('Growth Value')
plt.plot(ypoints, linestyle = 'dashed')
plt.show()



